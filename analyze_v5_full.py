#!/usr/bin/env python3
"""V5 è®­ç»ƒç»“æœå…¨é¢åˆ†æ"""

import pandas as pd
import numpy as np
import json
import re
import math
from scipy import stats
from collections import Counter

# ========== 0. æ£€æŸ¥ reward æ˜¯å¦"åæ‰" ==========
print("=" * 60)
print("0. Reward å¥åº·æ£€æŸ¥")
print("=" * 60)

# è¯»å– debug log
debug_log_path = "/workspace/reward_debug.log"
scores = []
buffer_ratios = []
works = []
consumptions = []
work_targets = []
barrier_thresholds = []
overwork_pens = []
layer2_pens = []
macro_rewards = []
work_contribs = []

try:
    with open(debug_log_path, 'r') as f:
        content = f.read()
    
    # è§£æ debug log
    pattern = r'\[(\d+)\].*?buf=([0-9.]+).*?work=([0-9.]+).*?tgt=([0-9.]+).*?bar=([0-9.]+).*?wr=([0-9.-]+).*?owp=([0-9.-]+).*?l2=([0-9.-]+).*?macro=([0-9.-]+).*?total=([0-9.-]+)'
    matches = re.findall(pattern, content)
    
    for m in matches:
        idx, buf, work, tgt, bar, wr, owp, l2, macro, total = m
        buffer_ratios.append(float(buf))
        works.append(float(work))
        work_targets.append(float(tgt))
        barrier_thresholds.append(float(bar))
        overwork_pens.append(float(owp))
        layer2_pens.append(float(l2))
        macro_rewards.append(float(macro))
        scores.append(float(total))
        work_contribs.append(float(wr))
    
    print(f"ä» debug log è§£æäº† {len(scores)} æ¡è®°å½•")
except Exception as e:
    print(f"è¯»å– debug log å¤±è´¥: {e}")

# è¯»å–éªŒè¯é›†
val_path = "/workspace/QWEN2.5_42_GRPO_700step-/QWEN2.5_42_GRPO_1/data/verl_dataset_small/val.parquet"
df = pd.read_parquet(val_path)

def parse_extra_info(e):
    if isinstance(e, str):
        try:
            return json.loads(e)
        except:
            return {}
    return e if isinstance(e, dict) else {}

df['extra_parsed'] = df['extra_info'].apply(parse_extra_info)
df['buffer_ratio'] = df['extra_parsed'].apply(lambda x: x.get('buffer_ratio', None))
df['regime'] = df['extra_parsed'].apply(lambda x: x.get('regime', 'normal'))
df['regime_strength'] = df['extra_parsed'].apply(lambda x: x.get('regime_strength', None))
df['dpi'] = df['extra_parsed'].apply(lambda x: x.get('dpi', None))

# ä»è®­ç»ƒæ—¥å¿—è·å–éªŒè¯åˆ†æ•°
train_log_path = "/workspace/train_v5_reward.log"
val_scores = []
val_works = []
val_cons = []

try:
    with open(train_log_path, 'r') as f:
        log_content = f.read()
    
    # æå–éªŒè¯æ—¶çš„è¾“å‡º
    # å¯»æ‰¾ JSON è¾“å‡º
    json_pattern = r'\{"work":\s*([0-9.]+),\s*"consumption":\s*([0-9.]+)\}'
    json_matches = re.findall(json_pattern, log_content)
    
    for w, c in json_matches[-200:]:  # å–æœ€å 200 ä¸ªï¼ˆéªŒè¯é›†å¤§å°ï¼‰
        val_works.append(float(w))
        val_cons.append(float(c))
    
    # æå– reward å‡å€¼
    reward_pattern = r"val-core/econ_agent/reward/mean@1[':]\s*np\.float64\(([0-9.-]+)\)"
    reward_matches = re.findall(reward_pattern, log_content)
    if reward_matches:
        print(f"éªŒè¯ reward å‡å€¼: {reward_matches[-1]}")
    
    # æå–åˆ†æ•°åˆ†å¸ƒ
    score_pattern = r"critic/score/(mean|max|min):([0-9.-]+)"
    score_matches = re.findall(score_pattern, log_content)
    if score_matches:
        score_dict = {k: float(v) for k, v in score_matches[-3:]}
        print(f"Score åˆ†å¸ƒ: mean={score_dict.get('mean', 'N/A'):.4f}, "
              f"max={score_dict.get('max', 'N/A'):.4f}, "
              f"min={score_dict.get('min', 'N/A'):.4f}")

except Exception as e:
    print(f"è¯»å–è®­ç»ƒæ—¥å¿—å¤±è´¥: {e}")

print(f"\nä»éªŒè¯è¾“å‡ºè§£æäº† {len(val_works)} ä¸ª work å€¼, {len(val_cons)} ä¸ª consumption å€¼")

# æ£€æŸ¥ NaN/Inf
print("\n--- NaN/Inf æ£€æŸ¥ ---")
br_valid = df['buffer_ratio'].dropna()
print(f"buffer_ratio: æœ‰æ•ˆ {len(br_valid)}/{len(df)}, NaN/Inf: {len(df) - len(br_valid)}")

rs_valid = df['regime_strength'].dropna()
print(f"regime_strength: æœ‰æ•ˆ {len(rs_valid)}/{len(df)}, NaN/Inf: {len(df) - len(rs_valid)}")

dpi_valid = df['dpi'].dropna()
print(f"dpi: æœ‰æ•ˆ {len(dpi_valid)}/{len(df)}, NaN/Inf: {len(df) - len(dpi_valid)}")

# è´Ÿåˆ†å æ¯”ï¼ˆä» debug logï¼‰
if scores:
    neg_ratio = sum(1 for s in scores if s < 0) / len(scores)
    print(f"\n--- è´Ÿåˆ†å æ¯” ---")
    print(f"è´Ÿåˆ† (<0): {neg_ratio*100:.1f}%")
    print(f"æ¥è¿‘é›¶ (-0.1~0.1): {sum(1 for s in scores if -0.1 <= s <= 0.1)/len(scores)*100:.1f}%")
    print(f"é«˜åˆ† (>0.3): {sum(1 for s in scores if s > 0.3)/len(scores)*100:.1f}%")

# Clip å‘½ä¸­ç‡
if scores:
    clip_low = sum(1 for s in scores if s <= -0.99) / len(scores)
    clip_high = sum(1 for s in scores if s >= 0.99) / len(scores)
    print(f"\n--- Clip å‘½ä¸­ç‡ ---")
    print(f"è¢« clip åˆ° -1: {clip_low*100:.2f}%")
    print(f"è¢« clip åˆ° +1: {clip_high*100:.2f}%")

# ========== 1. åŠ¨ä½œé”æ­»æ£€æŸ¥ ==========
print("\n" + "=" * 60)
print("1. åŠ¨ä½œåˆ†å¸ƒåˆ†æ")
print("=" * 60)

if val_works:
    works_arr = np.array(val_works)
    cons_arr = np.array(val_cons)
    
    # å”¯ä¸€å€¼æ•°é‡
    work_unique = len(set(val_works))
    cons_unique = len(set(val_cons))
    pairs = list(zip(val_works, val_cons))
    pair_unique = len(set(pairs))
    
    print(f"Work å”¯ä¸€å€¼æ•°é‡: {work_unique}")
    print(f"Consumption å”¯ä¸€å€¼æ•°é‡: {cons_unique}")
    print(f"åŠ¨ä½œç»„åˆæ•°: {pair_unique}")
    
    # Top-K åˆ†æ
    print("\n--- Work Top-5 åˆ†å¸ƒ ---")
    work_counter = Counter(val_works)
    for val, cnt in work_counter.most_common(5):
        print(f"  work={val:.2f}: {cnt} æ¬¡ ({cnt/len(val_works)*100:.1f}%)")
    
    print("\n--- Consumption Top-5 åˆ†å¸ƒ ---")
    cons_counter = Counter(val_cons)
    for val, cnt in cons_counter.most_common(5):
        print(f"  cons={val:.2f}: {cnt} æ¬¡ ({cnt/len(val_cons)*100:.1f}%)")
    
    print("\n--- åŠ¨ä½œç»„åˆ Top-5 ---")
    pair_counter = Counter(pairs)
    for (w, c), cnt in pair_counter.most_common(5):
        print(f"  (work={w:.2f}, cons={c:.2f}): {cnt} æ¬¡ ({cnt/len(pairs)*100:.1f}%)")
    
    # åŸºæœ¬ç»Ÿè®¡
    print(f"\n--- Work ç»Ÿè®¡ ---")
    print(f"  mean={works_arr.mean():.3f}, std={works_arr.std():.3f}")
    print(f"  min={works_arr.min():.2f}, max={works_arr.max():.2f}")
    
    print(f"\n--- Consumption ç»Ÿè®¡ ---")
    print(f"  mean={cons_arr.mean():.3f}, std={cons_arr.std():.3f}")
    print(f"  min={cons_arr.min():.2f}, max={cons_arr.max():.2f}")

# ========== 2. Work vs Buffer Ratio ==========
print("\n" + "=" * 60)
print("2. æ ¸å¿ƒå¾®è§‚é€»è¾‘: Work vs Buffer Ratio")
print("=" * 60)

# ä½¿ç”¨éªŒè¯é›†çš„ buffer_ratio
br_values = df['buffer_ratio'].values
if len(val_works) == len(br_values):
    # ç›¸å…³æ€§åˆ†æ
    valid_mask = ~np.isnan(br_values)
    br_clean = br_values[valid_mask]
    work_clean = np.array(val_works)[valid_mask]
    
    if len(br_clean) > 10:
        pearson_r, pearson_p = stats.pearsonr(br_clean, work_clean)
        spearman_r, spearman_p = stats.spearmanr(br_clean, work_clean)
        
        print(f"Pearson r = {pearson_r:.4f} (p={pearson_p:.4f})")
        print(f"Spearman Ï = {spearman_r:.4f} (p={spearman_p:.4f})")
        
        if pearson_r < -0.1:
            print("âœ… è´Ÿç›¸å…³æ–¹å‘æ­£ç¡®")
        elif pearson_r > 0.1:
            print("âš ï¸ æ­£ç›¸å…³ï¼Œä¸é¢„æœŸç›¸å")
        else:
            print("âš ï¸ ç›¸å…³æ€§æ¥è¿‘ 0ï¼Œå¾®è§‚é€»è¾‘æœªä½“ç°")
    
    # åˆ†ç»„å‡å€¼
    print("\n--- åˆ†ç»„å‡å€¼ (BR ä¸‰æ®µ) ---")
    low_mask = br_values < 2
    mid_mask = (br_values >= 2) & (br_values <= 3.5)
    high_mask = br_values > 3.5
    
    work_arr = np.array(val_works)
    
    low_work = work_arr[low_mask].mean() if low_mask.sum() > 0 else np.nan
    mid_work = work_arr[mid_mask].mean() if mid_mask.sum() > 0 else np.nan
    high_work = work_arr[high_mask].mean() if high_mask.sum() > 0 else np.nan
    
    print(f"  BR < 2:     work å‡å€¼ = {low_work:.3f} (n={low_mask.sum()})")
    print(f"  BR 2~3.5:   work å‡å€¼ = {mid_work:.3f} (n={mid_mask.sum()})")
    print(f"  BR > 3.5:   work å‡å€¼ = {high_work:.3f} (n={high_mask.sum()})")
    
    if low_work > mid_work > high_work:
        print("âœ… Work éš BR é€’å‡ï¼Œç¬¦åˆé¢„æœŸ")
    else:
        print("âš ï¸ Work æœªéš BR é€’å‡")
    
    # é«˜ BR é”™ä¾‹
    very_high_br = br_values > 4
    high_work_mask = work_arr >= 0.8
    error_mask = very_high_br & high_work_mask
    error_rate = error_mask.sum() / very_high_br.sum() if very_high_br.sum() > 0 else 0
    print(f"\n--- é«˜ BR é”™ä¾‹ ---")
    print(f"  BR > 4 ä¸” work >= 0.8: {error_mask.sum()} / {very_high_br.sum()} ({error_rate*100:.1f}%)")

# ========== 3. Consumption vs Regime ==========
print("\n" + "=" * 60)
print("3. æ ¸å¿ƒå®è§‚é€»è¾‘: Consumption vs Regime")
print("=" * 60)

regime_values = df['regime'].values
if len(val_cons) == len(regime_values):
    cons_arr = np.array(val_cons)
    
    print("\n--- å„ Regime æ¶ˆè´¹ç»Ÿè®¡ ---")
    regimes = ['recession', 'normal', 'boom']
    regime_stats = {}
    
    for r in regimes:
        mask = regime_values == r
        if mask.sum() > 0:
            cons_r = cons_arr[mask]
            regime_stats[r] = {
                'mean': cons_r.mean(),
                'std': cons_r.std(),
                'n': mask.sum()
            }
            print(f"  {r:10s}: mean={cons_r.mean():.3f}, std={cons_r.std():.3f}, n={mask.sum()}")
    
    # Boom vs Recession å·®å¼‚
    if 'boom' in regime_stats and 'recession' in regime_stats:
        diff = regime_stats['boom']['mean'] - regime_stats['recession']['mean']
        print(f"\n  Boom - Recession å·®å¼‚: {diff:+.4f}")
        
        if diff > 0.03:
            print("âœ… Boom æ¶ˆè´¹æ›´é«˜ï¼Œç¬¦åˆé¢„æœŸ")
        elif diff > 0:
            print("âš ï¸ æ–¹å‘æ­£ç¡®ä½†å·®å¼‚è¾ƒå° (<0.03)")
        else:
            print("âŒ Recession æ¶ˆè´¹æ›´é«˜ï¼Œä¸é¢„æœŸç›¸å")
    
    # æ ·æœ¬ä¸å‡è¡¡æ£€æŸ¥
    print("\n--- Regime æ ·æœ¬åˆ†å¸ƒ ---")
    for r in regimes:
        cnt = (regime_values == r).sum()
        print(f"  {r}: {cnt} ({cnt/len(regime_values)*100:.1f}%)")

# ========== 4. ä½åˆ†æ ·æœ¬ Top-K è¯Šæ–­ ==========
print("\n" + "=" * 60)
print("4. ä½åˆ†æ ·æœ¬ Top-10 è¯Šæ–­")
print("=" * 60)

if scores and len(val_works) >= 10:
    # åˆå¹¶æ•°æ®
    n = min(len(scores), len(val_works), len(br_values))
    
    data = []
    for i in range(n):
        data.append({
            'idx': i,
            'score': scores[i] if i < len(scores) else np.nan,
            'work': val_works[i] if i < len(val_works) else np.nan,
            'cons': val_cons[i] if i < len(val_cons) else np.nan,
            'br': br_values[i] if i < len(br_values) else np.nan,
            'regime': regime_values[i] if i < len(regime_values) else 'unknown',
            'work_target': work_targets[i] if i < len(work_targets) else np.nan,
            'barrier': barrier_thresholds[i] if i < len(barrier_thresholds) else np.nan,
            'overwork_pen': overwork_pens[i] if i < len(overwork_pens) else np.nan,
            'layer2_pen': layer2_pens[i] if i < len(layer2_pens) else np.nan,
            'macro_reward': macro_rewards[i] if i < len(macro_rewards) else np.nan,
        })
    
    # æŒ‰åˆ†æ•°æ’åºï¼Œå–æœ€ä½ 10 ä¸ª
    data_sorted = sorted(data, key=lambda x: x['score'] if not np.isnan(x['score']) else 999)
    
    print("æœ€ä½åˆ† 10 ä¸ªæ ·æœ¬ï¼š")
    print("-" * 80)
    for i, d in enumerate(data_sorted[:10]):
        print(f"[{i+1}] Score={d['score']:.3f} | BR={d['br']:.2f} | Regime={d['regime']}")
        print(f"    Work={d['work']:.2f} (tgt={d['work_target']:.2f}, bar={d['barrier']:.2f})")
        print(f"    Cons={d['cons']:.2f}")
        print(f"    Penalties: overwork={d['overwork_pen']:.3f}, l2={d['layer2_pen']:.3f}, macro={d['macro_reward']:.3f}")
        print()
    
    # ç»Ÿè®¡ä½åˆ†æ ·æœ¬çš„ç‰¹å¾
    low_score_data = data_sorted[:20]
    low_regimes = [d['regime'] for d in low_score_data]
    low_brs = [d['br'] for d in low_score_data if not np.isnan(d['br'])]
    low_works = [d['work'] for d in low_score_data if not np.isnan(d['work'])]
    
    print("\n--- ä½åˆ†æ ·æœ¬ç‰¹å¾ç»Ÿè®¡ ---")
    print(f"Regime åˆ†å¸ƒ: {Counter(low_regimes)}")
    print(f"BR å‡å€¼: {np.mean(low_brs):.2f}")
    print(f"Work å‡å€¼: {np.mean(low_works):.2f}")

# ========== 5. çº¦æŸè§¦å‘ç‡ ==========
print("\n" + "=" * 60)
print("5. çº¦æŸè§¦å‘ç‡")
print("=" * 60)

if val_works and val_cons:
    work_arr = np.array(val_works)
    cons_arr = np.array(val_cons)
    
    # Work/Cons è¶Šç•Œ
    work_out = ((work_arr < 0) | (work_arr > 1)).sum()
    cons_out = ((cons_arr < 0) | (cons_arr > 1)).sum()
    print(f"Work è¶Šç•Œ (<0 æˆ– >1): {work_out} ({work_out/len(work_arr)*100:.2f}%)")
    print(f"Cons è¶Šç•Œ (<0 æˆ– >1): {cons_out} ({cons_out/len(cons_arr)*100:.2f}%)")
    
    # Extreme penalty
    extreme_work = ((work_arr < 0.05) | (work_arr > 0.95)).sum()
    extreme_cons = ((cons_arr < 0.05) | (cons_arr > 0.95)).sum()
    print(f"\nExtreme Work (<0.05 æˆ– >0.95): {extreme_work} ({extreme_work/len(work_arr)*100:.1f}%)")
    print(f"Extreme Cons (<0.05 æˆ– >0.95): {extreme_cons} ({extreme_cons/len(cons_arr)*100:.1f}%)")
    
    # Overconsume
    overconsume = (cons_arr > 0.90).sum()
    print(f"\nOverconsume (cons > 0.90): {overconsume} ({overconsume/len(cons_arr)*100:.1f}%)")
    
    # Overwork Layer2
    overwork_l2 = (work_arr > 0.86).sum()
    print(f"Overwork Layer2 (work > 0.86): {overwork_l2} ({overwork_l2/len(work_arr)*100:.1f}%)")

# ========== 6. é€‰æ‹©å»ºè®® ==========
print("\n" + "=" * 60)
print("6. Checkpoint é€‰æ‹©å»ºè®®")
print("=" * 60)

print("\nè¯„ä¼°ç»´åº¦ï¼š")
print("-" * 40)

# 1. Work-BR ç›¸å…³æ€§
if 'pearson_r' in dir():
    if pearson_r < -0.1:
        print("âœ… Work-BR è´Ÿç›¸å…³: æ˜¯")
    else:
        print("âŒ Work-BR è´Ÿç›¸å…³: å¦")

# 2. Regime-Consumption æ–¹å‘
if 'diff' in dir():
    if diff > 0:
        print("âœ… Boom > Recession æ¶ˆè´¹: æ˜¯")
    else:
        print("âŒ Boom > Recession æ¶ˆè´¹: å¦")

# 3. åŠ¨ä½œé”æ­»
if val_works:
    top1_ratio = work_counter.most_common(1)[0][1] / len(val_works)
    if top1_ratio < 0.5:
        print(f"âœ… åŠ¨ä½œæœªé”æ­»: Top-1 å æ¯” {top1_ratio*100:.1f}%")
    else:
        print(f"âŒ åŠ¨ä½œé”æ­»: Top-1 å æ¯” {top1_ratio*100:.1f}%")

# 4. å¹³å‡åˆ†
if scores:
    avg_score = np.mean(scores)
    print(f"ğŸ“Š å¹³å‡åˆ†: {avg_score:.3f}")

print("\n" + "=" * 60)
print("åˆ†æå®Œæˆ")
print("=" * 60)

